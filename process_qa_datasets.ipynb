{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "\n",
    "PROJ_DIR = \"~/Dialect_Bias/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions for making rule dialects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('data/attestA_rules.json', 'r') as f:\n",
    "    attest_a_rules = json.load(f)\n",
    "\n",
    "rule_list = list(attest_a_rules.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_save(save_df, save_dir, file_name): \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "    save_df.to_csv(file_path, index=False)\n",
    "    \n",
    "\n",
    "def generate_rule_transformed_dataset(df, dialect, row_to_transform=\"question\", rows_to_save = [\"id\", \"context\", \"answers\"], save_dir=\"data/oblig_rule_transforms\"):\n",
    "    tranformed_texts = []\n",
    "    rules_executed = []\n",
    "    ids_so_far = []\n",
    "    failed_ids = []\n",
    "\n",
    "    def save_helper(ids_so_far, tranformed_texts, rules_executed):\n",
    "        save_df = pd.DataFrame({\"id\": ids_so_far, \"transformed_text\": tranformed_texts, \"rules_executed\": rules_executed})\n",
    "        save_df = save_df.merge(df[rows_to_save], on=\"id\")\n",
    "        save_df[\"rule_transform\"] = dialect.dialect_name\n",
    "        safe_save(save_df, save_dir, f\"{dialect.dialect_name}.csv\")\n",
    "        return save_df\n",
    "\n",
    "    iterator = tqdm(df.iterrows(), total=df.shape[0])\n",
    "    for i, row in iterator: \n",
    "        \n",
    "        try: \n",
    "            # get dialect trasnformations \n",
    "            tranformed_texts.append(dialect.transform(row[row_to_transform]))\n",
    "            \n",
    "            # get rules \n",
    "            rules_executed.append(dialect.executed_rules) \n",
    "            ids_so_far.append(row[\"id\"])\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            failed_ids.append(row[\"id\"])\n",
    "\n",
    "    save_df = save_helper(ids_so_far, tranformed_texts, rules_executed)\n",
    "    return save_df, failed_ids\n",
    "\n",
    "def build_dialects_for_each_rule(rule_list, df, row_to_transform=\"question\", rows_to_save = [\"id\", \"context\", \"answers\"], save_dir=\"data/oblig_rule_transforms\"): \n",
    "    dialect_df_list = []\n",
    "    all_failed_ids = [] \n",
    "\n",
    "    for r in tqdm(rule_list): \n",
    "        dialect =  Dialects.DialectFromFeatureList(feature_list=[r], dialect_name=r)\n",
    "        dialect_df, failed_ids = generate_rule_transformed_dataset( df, dialect, save_dir=save_dir, rows_to_save=rows_to_save)\n",
    "        all_failed_ids.extend(failed_ids)\n",
    "        dialect_df_list.append(dialect_df)\n",
    "\n",
    "    \n",
    "    return dialect_df_list, all_failed_ids\n",
    "\n",
    "def load_in_rules(rule_list, save_dir): \n",
    "    df_list = [] \n",
    "    for r in rule_list:\n",
    "        df = pd.read_csv(os.path.join(save_dir, f\"{r}.csv\"))\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def get_slice_with_exec(rules_df, exec_col = \"rules_executed\"): \n",
    "    return rules_df[rules_df[\"rules_executed\"] != \"{}\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process transformed datasets together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "def load_in_rules(rule_list, save_dir, pair=False): \n",
    "    df_list = [] \n",
    "    for r in rule_list:\n",
    "        filepath = os.path.join(save_dir, f\"{r}.csv\")\n",
    "        if pair: \n",
    "            rule_pair_name = \"+\".join(r)\n",
    "            filepath = os.path.join(save_dir, f\"{rule_pair_name}.csv\")\n",
    "        df = pd.read_csv(filepath)\n",
    "        df_list.append(df)\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "def get_slice_with_exec(rules_df, exec_col = \"rules_executed\"): \n",
    "    return rules_df[rules_df[\"rules_executed\"] != \"{}\"]\n",
    "\n",
    "def safe_save(save_df, save_dir, file_name): \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    file_path = os.path.join(save_dir, file_name)\n",
    "    save_df.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mmlu\"\n",
    "rules = \"pair\"\n",
    "\n",
    "# rule_list = [[\"existential_it\", \"drop_copula_be_NP\"], \n",
    "#              [\"existential_it\", \"drop_aux_wh\"],\n",
    "#              [\"existential_it\", \"drop_aux_yn\"],\n",
    "#              [\"existential_it\", \"negative_concord\"],\n",
    "#              [\"existential_it\", \"remove_det_indefinite\"],\n",
    "#              [\"existential_it\", \"plural_interrogative\"],\n",
    "#              [\"existential_it\", \"remove_det_definite\"],\n",
    "#              ]\n",
    "rule_list = [\n",
    "    [\"null_prepositions\", \"drop_copula_be_NP\"], \n",
    "    [\"null_prepositions\", \"one_relativizer\"], \n",
    "    [\"null_prepositions\", \"one_relativizer\", \"drop_copula_be_NP\"], \n",
    "]\n",
    "\n",
    "save_dir = f\"data/{dataset_name}/{rules}_transforms\"\n",
    "\n",
    "loaded_in_rules = load_in_rules(rule_list, save_dir=save_dir, pair=True)\n",
    "slice_with_exec = get_slice_with_exec(loaded_in_rules, exec_col = \"rules_executed\") \n",
    "combined_dir = os.path.join(save_dir, \"combined\")\n",
    "\n",
    "if dataset_name == \"boolq\": \n",
    "    # additional post-processing step convert to yes and no \n",
    "    slice_with_exec[\"answer\"] = slice_with_exec[\"answer\"].apply(lambda x: \"yes\" if x == True else \"no\")\n",
    "\n",
    "# safe_save(slice_with_exec, combined_dir, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "\n",
    "def clean_executed_rules(x): \n",
    "    rule_dict = ast.literal_eval(x)\n",
    "    return [v[\"type\"] for _ , v in rule_dict.items()] if x else []\n",
    "\n",
    "def get_multi_rule(rules_df, rule_list): \n",
    "    rules_df[\"rules_executed_list\"] = rules_df[\"rules_executed\"].apply(clean_executed_rules)\n",
    "    rules_df[\"rule_executed_set\"] = rules_df[\"rules_executed_list\"].apply(lambda x : list(set(x)))\n",
    "    rule_slice_list = [] \n",
    "    for rules in rule_list: \n",
    "        transform_name = \"+\".join(rules)\n",
    "        rules_df_slice = rules_df[rules_df[\"rule_transform\"] == transform_name]\n",
    "        rules_df_slice = rules_df_slice[rules_df_slice[\"rule_executed_set\"].apply(lambda x: len(x) == len(rules))]\n",
    "        rule_slice_list.append(rules_df_slice)\n",
    "    return pd.concat(rule_slice_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_rule_df = get_multi_rule(slice_with_exec, rule_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_save(multi_rule_df, combined_dir, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['high_school_government_and_politics', 'security_studies',\n",
       "       'sociology', 'high_school_european_history', 'college_biology',\n",
       "       'high_school_psychology', 'astronomy', 'electrical_engineering',\n",
       "       'logical_fallacies', 'nutrition', 'high_school_biology',\n",
       "       'high_school_macroeconomics', 'virology', 'machine_learning',\n",
       "       'jurisprudence', 'professional_psychology', 'abstract_algebra',\n",
       "       'econometrics', 'high_school_mathematics',\n",
       "       'high_school_computer_science', 'philosophy', 'college_chemistry',\n",
       "       'human_sexuality', 'high_school_chemistry', 'human_aging',\n",
       "       'anatomy', 'management', 'college_medicine', 'computer_security',\n",
       "       'marketing', 'conceptual_physics', 'medical_genetics',\n",
       "       'public_relations', 'world_religions', 'high_school_us_history',\n",
       "       'international_law', 'professional_law', 'high_school_physics',\n",
       "       'moral_disputes', 'high_school_world_history',\n",
       "       'professional_medicine', 'miscellaneous',\n",
       "       'high_school_microeconomics', 'business_ethics',\n",
       "       'clinical_knowledge', 'formal_logic', 'college_physics',\n",
       "       'high_school_statistics', 'professional_accounting',\n",
       "       'elementary_mathematics', 'college_mathematics', 'moral_scenarios',\n",
       "       'college_computer_science', 'high_school_geography',\n",
       "       'us_foreign_policy', 'prehistory', 'global_facts'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_rule_df[\"subject\"].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multivalue_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
